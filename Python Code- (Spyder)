import numpy as np
import os
import cv2

data=[] 
'''creating list'''
t=[]
x=0
count=0

directory=r'C:\Users\HP\Downloads\dod vs catt\PetImages\Cat'

imagesize=(100,100)

for img in os.listdir(directory):
    x+=1
    img_path=os.path.join(directory,img)
    image=cv2.imread(img_path)
    try:
        image=cv2.resize(image,imagesize)
        data.append(image)
    except:
        count+=1
        pass
    
print(count)

directory=r'C:\Users\HP\Downloads\dod vs catt\PetImages\Dog'

for img in os.listdir(directory):
    x+=1
    img_path=os.path.join(directory,img)
    image=cv2.imread(img_path)
    try:
        image=cv2.resize(image,imagesize)
        data.append(image)
    except:
        count+=1
        pass

print(count)
data=np.array(data)
'''
for single image
'''
directory=r'C:\Users\HP\Downloads\dod vs catt\PetImages\single'
for img in os.listdir(directory):
    x+=1
    img_path=os.path.join(directory,img)
    image=cv2.imread(img_path)
    try:
        image=cv2.resize(image,imagesize)
        t.append(image)
    except:
        count+=1
        pass
t=np.array(t)
print(t.shape)
t=t.reshape((-1,t.shape[0]))


print(data.shape)

data=data.reshape((-1,data.shape[0]))
'''to control overflow,normalizing data//feature scaling'''

data= data/255

x_train=data[:,:796]
x_test=data[:,796:996]
print(x_train.shape)

x_train=np.append(x_train,data[:,996:1796],axis=1)
x_test=np.append(x_test,data[:,1796:],axis=1)

print(x_train.shape)
print(x_test.shape)

y_train=np.zeros((1,796))
y_test=np.zeros((1,200))

y_train=np.append(y_train,np.full((1,800),1),axis=1)
y_test=np.append(y_test,np.full((1,201),1),axis=1)

print(y_train.shape)
print(y_test.shape)
def sigmoid(z):
    s=1/(1+np.exp(-z))
    return s

def initialization(n_x):
    '''n_x = no. of features=100*100*3'''
    w = np.random.randn(n_x,1)*0.01
    b = 0.0
    return w,b


def propagate(w, b, x, y):
    
    Z=np.dot(w.T,x)+b

    A=sigmoid(Z)
    
    return A

def gradient_descent(w,b,x,y,n_i,lr):
    
    m=x.shape[1]
    
    for i in range(n_i):
        A=propagate(w,b,x,y)
      
        cost = (1./m) * (-np.dot(y,np.log(A).T) - np.dot(1-y, np.log(1-A).T))
        '''to check hamari values kitni match kr rhe hai'''
        if i%75==0:
            print(cost)
        
        dw = (np.dot(x,(A-y).T))/m
        db = (np.sum(A-y))/m
        
        w = w - (lr*dw)
        b = b - (lr*db)
        
    return w,b

def prediction(w,b,x):
    m = x.shape[1]
    Y_prediction = np.zeros((1, m))
    w = w.reshape(x.shape[0], 1)
    
    A = sigmoid(w.T.dot(x) + b)
    
    for i in range(A.shape[1]):
        if A[0, i] <= 0.5 :
            Y_prediction[0,i] = 0
        else:
            Y_prediction[0,i] = 1
    
    return Y_prediction

def model(x_train, y_train, x_test, y_test, imgg , n_i, lr):
    
    w,b=initialization(x_train.shape[0])
    
    w,b=gradient_descent(w, b, x_train, y_train, n_i, lr)
    
    
    Y_prediction_test = prediction(w, b, x_test)
    Y_prediction_train = prediction(w, b, x_train)
    
    print("train accuracy: {} %".format(100 - np.mean(np.abs(Y_prediction_train - y_train)) * 100))
    print("test accuracy: {} %".format(100 - np.mean(np.abs(Y_prediction_test - y_test)) * 100))
    
    r=prediction(w,b,imgg)
    print(r)
    
model(x_train, y_train, x_test, y_test, t , n_i = 1000, lr = 0.005)
'''
learning rate and iterations are hyperparameter...t

lr bada underfit
lr chota or n_i overfit
'''
